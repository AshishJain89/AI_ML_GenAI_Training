{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check the correct virtual enviornment\n",
    "\n",
    "import sys\n",
    "sys.prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model='gemma2-9b-it', groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation on Human , System Message\n",
    "\n",
    "https://python.langchain.com/api_reference/core/messages.html\n",
    "\n",
    "https://python.langchain.com/api_reference/core/messages/langchain_core.messages.system.SystemMessage.html\n",
    "\n",
    "https://python.langchain.com/api_reference/core/messages/langchain_core.messages.human.HumanMessage.html\n",
    "\n",
    "https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.AIMessage.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content='Hi my name is Ankur and I am the chief AI engineer.')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 1 \n",
    "\n",
    "Creating a simple chatbot where messages are passed as sequence and the chat model is able to remember the information provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content='Hi my name is Ankur and I am the chief AI engineer.'),\n",
    "            AIMessage(content=\"Hello Ankur, it's nice to meet you! As a large language model, I'm always eager to learn from experienced AI engineers like yourself. \\n\\nWhat are you working on these days?  Is there anything I can help you with?\\n\"),\n",
    "            HumanMessage(\"What is my name and what I do?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2\n",
    "\n",
    "- Message History\n",
    "\n",
    "We can use a Message History class to wrap our model and make it stateful. This will keep track of inputs and outputs of the model, and store them in some datastore. Future interactions will then load those messages and pass them into the chain as part of the input. Let's see how to use this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation for \n",
    "\n",
    "\n",
    "- ChatMessageHistory https://python.langchain.com/api_reference/community/chat_message_histories.html\n",
    "\n",
    "\n",
    "- BaseChatMessageHistory   https://python.langchain.com/api_reference/core/chat_history/langchain_core.chat_history.BaseChatMessageHistory.html\n",
    "\n",
    "\n",
    "- RunnableWithMessageHistory   https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory ### Chat message history stores a history of the message interactions in a chat.\n",
    "\n",
    "\n",
    "from langchain_core.chat_history import BaseChatMessageHistory   ###  Abstract base class for storing chat message history.\n",
    "\n",
    "\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory  ### RunnableWithMessageHistory wraps another Runnable and manages the chat message history for it; it is responsible for reading and updating the chat message history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When multiple users interact with the chat model how we will make sure that one session is completly different from another sesssion ?\n",
    "\n",
    "We will create a function as below -\n",
    "\n",
    "1) It accepts session ID as input. It will be used to distinguish one session from another\n",
    "2) It returns the object of type BaseChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "### function that retrives chat history for a specific session id\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Interact with LLM model based on chat history\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define a config parameter that defines the session id for a perticular session\n",
    "\n",
    "### Here we have hardcoded our session id as 'chat1'\n",
    "\n",
    "config = {'configurable' : {'session_id' : 'chat1'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content = \"My name is Ashish and I am an DevOps engineer\")]\n",
    "with_message_history.invoke(messages, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lets ask the chat model another question with respect to same session id\n",
    "\n",
    "with_message_history.invoke([HumanMessage(content='What is my name and what I do?')], config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lets create a new sesson id\n",
    "\n",
    "config_2 = {'configurable' : {'session_id' : 'chat2'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content='My name is Suresh and I am a CA')]\n",
    "with_message_history.invoke(messages, config=config_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lets ask the question to the chat model with respect to 'chat2' session id\n",
    "\n",
    "with_message_history.invoke([HumanMessage(content='What is my name and what I do?')], config=config_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lets create a new session id and ask the same question as previously asked\n",
    "\n",
    "config_3 = {'configurable' : {'session_id' : 'chat3'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history.invoke([HumanMessage(content='What is my name and what I do?')], config=config_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
